{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from lstm_cnn_net import lstm_cnn\n",
    "from lstm_net import LSTM\n",
    "from cnn_net import MyNet\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([715, 301, 12]) torch.Size([46, 301, 12]) torch.Size([47, 301, 12])\n",
      "torch.Size([715]) torch.Size([46]) torch.Size([47])\n"
     ]
    }
   ],
   "source": [
    "names = ['AC', 'AD', 'BC', 'BD']\n",
    "types = ['train', 'val', 'test']\n",
    "#load data\n",
    "#mac: /Users/syunsei/Desktop/SII2025/process_data/classifier/\n",
    "#win: C:\\Github_LIU\\SII2025\\process_data\\classifier\\\n",
    "for name in names:\n",
    "    for type in types:\n",
    "        globals()[name + '_' + type] = np.load('/Users/syunsei/Desktop/SII2025/process_data/classifier/' + name + '_' + type + '.npy')\n",
    "        \n",
    "X_train = np.concatenate((AC_train, AD_train, BC_train, BD_train), axis=0)\n",
    "X_val = np.concatenate((AC_val, AD_val, BC_val, BD_val), axis=0)\n",
    "X_test = np.concatenate((AC_test, AD_test, BC_test, BD_test), axis=0)\n",
    "y_train = np.concatenate((np.zeros(AC_train.shape[0]), np.ones(AD_train.shape[0]), np.ones(BC_train.shape[0]) * 2, np.ones(BD_train.shape[0]) * 3), axis=0)\n",
    "y_val = np.concatenate((np.zeros(AC_val.shape[0]), np.ones(AD_val.shape[0]), np.ones(BC_val.shape[0]) * 2, np.ones(BD_val.shape[0]) * 3), axis=0)\n",
    "y_test = np.concatenate((np.zeros(AC_test.shape[0]), np.ones(AD_test.shape[0]), np.ones(BC_test.shape[0]) * 2, np.ones(BD_test.shape[0]) * 3), axis=0)\n",
    "\n",
    "#归一化\n",
    "# def min_max_normalize(data):\n",
    "#     # 初始化归一化后的特征矩阵\n",
    "#     normalized_features = np.zeros_like(data)\n",
    "#     # 对每个 dim 进行归一化\n",
    "#     for i in range(data.shape[1]):\n",
    "#         dim_values = data[:, :, i]\n",
    "#         min_val = np.min(dim_values)\n",
    "#         max_val = np.max(dim_values)\n",
    "#         # 使用最小-最大归一化公式\n",
    "#         normalized_features[:, :, i] = (dim_values - min_val) / (max_val - min_val)\n",
    "#     return normalized_features\n",
    "\n",
    "# X_train = min_max_normalize(X_train)\n",
    "# X_val = min_max_normalize(X_val)\n",
    "# X_test = min_max_normalize(X_test)\n",
    "\n",
    "#split data into training and testing and validation\n",
    "'''X_train=np.concatenate ((X_train[:,:,0:3],X_train[:,:,6:9]), axis=2)\n",
    "X_val=np.concatenate ((X_val[:,:,0:3],X_val[:,:,6:9]), axis=2)\n",
    "X_test=np.concatenate ((X_test[:,:,0:3],X_test[:,:,6:9]), axis=2)'''\n",
    "X_train=torch.tensor(X_train,dtype=torch.float32)\n",
    "X_val=torch.tensor(X_val,dtype=torch.float32)\n",
    "X_test=torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train=torch.tensor(y_train,dtype=torch.long)\n",
    "y_val=torch.tensor(y_val,dtype=torch.long)\n",
    "y_test=torch.tensor(y_test,dtype=torch.long)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# #draw X_train\n",
    "# print(X_train[66].shape)\n",
    "# plt.plot(X_train[66])\n",
    "# plt.show()\n",
    "'''\n",
    "batch_size = 100\n",
    "train_data = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_data = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val))\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_data = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test))\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)'''\n",
    "\n",
    "#dataset\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=100)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=20)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "sequence_len = 301\n",
    "input_len = 12\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 4\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_cnn(\n",
      "  (conv1): Conv1d(12, 64, kernel_size=(9,), stride=(1,))\n",
      "  (conv2): Conv1d(12, 32, kernel_size=(5,), stride=(1,))\n",
      "  (conv3): Conv1d(12, 16, kernel_size=(5,), stride=(1,))\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (lstm): LSTM(12, 128, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = lstm_cnn(input_len, hidden_size, num_layers, num_classes).to(device)\n",
    "#model = MyNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 12, 5], expected input[100, 64, 147] to have 12 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m     29\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m plot_learning_curve(loss_list)\n",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, model, train_loader, loss_function)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''lifts = lifts.reshape(-1, sequence_len, input_len).to(device)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mlabels = labels.long().to(device)'''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m lifts, labels \u001b[38;5;241m=\u001b[39m lifts\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlifts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, labels)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SII2025/Model/classifier/lstm_cnn_net.py:25\u001b[0m, in \u001b[0;36mlstm_cnn.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 12, 5], expected input[100, 64, 147] to have 12 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "def train(num_epochs, model, train_loader, loss_function):\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, (lifts, labels) in enumerate(train_loader):\n",
    "            '''lifts = lifts.reshape(-1, sequence_len, input_len).to(device)\n",
    "            labels = labels.long().to(device)'''\n",
    "            lifts, labels = lifts.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(lifts)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (batch+1) % 2 == 0:\n",
    "                loss_list.append(loss.item())\n",
    "                print(f\"Epoch [{epoch+1}; Batch {batch+1}/{total_step}]; Loss: {loss.item():.4f}\")\n",
    "                \n",
    "loss_list = []\n",
    "#draw learning curve\n",
    "def plot_learning_curve(loss_list):\n",
    "    plt.plot(loss_list, label=\"loss\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "train(num_epochs, model, train_loader, loss_function)\n",
    "plot_learning_curve(loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 82.6086956521739%\n"
     ]
    }
   ],
   "source": [
    "def validate(model, val_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for lifts, labels in val_loader:\n",
    "            lifts = lifts.reshape(-1, sequence_len, input_len).to(device)\n",
    "            labels = labels.long().to(device)\n",
    "            \n",
    "            outputs = model(lifts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f\"Validation accuracy: {100 * correct / total}%\")\n",
    "\n",
    "validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 82.6086956521739%\n",
      "[[ 9  1  0  0]\n",
      " [ 2  8  0  2]\n",
      " [ 1  0 11  0]\n",
      " [ 1  1  0 10]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8314, Recall: 0.8292, F1: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82.6086956521739, 0.8314102564102565, 0.8291666666666667, 0.8249341238471674)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate(model, val_loader, sequence_len, input_len, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        \n",
    "        for lifts, labels in val_loader:\n",
    "            lifts = lifts.reshape(-1, sequence_len, input_len).to(device)\n",
    "            labels = labels.long().to(device)\n",
    "            \n",
    "            outputs = model(lifts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Accumulate labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Validation accuracy: {accuracy}%\")\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "        print(conf_matrix)\n",
    "        #plot confusion matrix\n",
    "        class_labels_conf = ['AC', 'AD', 'BC', 'BD']\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(conf_matrix, cmap='Blues')\n",
    "        ax.set_xticks(np.arange(len(class_labels_conf)))\n",
    "        ax.set_yticks(np.arange(len(class_labels_conf)))\n",
    "        ax.set_xticklabels(class_labels_conf)\n",
    "        ax.set_yticklabels(class_labels_conf)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        for i in range(len(class_labels_conf)):\n",
    "            for j in range(len(class_labels_conf)):\n",
    "                text = ax.text(j, i, conf_matrix[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "        ax.set_title(\"Confusion Matrix\")\n",
    "        fig.tight_layout()\n",
    "        plt.ylabel('Actual Label', fontsize=15)\n",
    "        plt.xlabel('Predicted Label', fontsize=15)\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate precision, recall, and F1 scor\n",
    "        precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "        recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# Assuming `model`, `val_loader`, `sequence_len`, `input_len`, and `device` are defined\n",
    "validate(model, val_loader, sequence_len, input_len, device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 65.95744680851064%\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for lifts, labels in test_loader:\n",
    "            lifts = lifts.reshape(-1, sequence_len, input_len).to(device)\n",
    "            labels = labels.long().to(device)\n",
    "            \n",
    "            outputs = model(lifts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f\"Test accuracy: {100 * correct / total}%\")\n",
    "\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
